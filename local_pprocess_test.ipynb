{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (0.13.0)\n",
      "Requirement already satisfied: shapely>=1.7.1 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from geopandas) (2.0.1)\n",
      "Requirement already satisfied: fiona>=1.8.19 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from geopandas) (1.9.4.post1)\n",
      "Requirement already satisfied: pyproj>=3.0.1 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from geopandas) (3.5.0)\n",
      "Requirement already satisfied: pandas>=1.1.0 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from geopandas) (2.0.2)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from geopandas) (21.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from fiona>=1.8.19->geopandas) (21.4.0)\n",
      "Requirement already satisfied: certifi in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from fiona>=1.8.19->geopandas) (2022.12.7)\n",
      "Requirement already satisfied: click~=8.0 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from fiona>=1.8.19->geopandas) (8.1.3)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from fiona>=1.8.19->geopandas) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from fiona>=1.8.19->geopandas) (0.7.2)\n",
      "Requirement already satisfied: six in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from fiona>=1.8.19->geopandas) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from pandas>=1.1.0->geopandas) (1.22.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from pandas>=1.1.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from pandas>=1.1.0->geopandas) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from pandas>=1.1.0->geopandas) (2022.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from packaging->geopandas) (3.0.9)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (1.22.4)\n",
      "Requirement already satisfied: shapely in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: numpy>=1.14 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from shapely) (1.22.4)\n",
      "Requirement already satisfied: pyproj in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (3.5.0)\n",
      "Requirement already satisfied: certifi in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from pyproj) (2022.12.7)\n",
      "Requirement already satisfied: fiona in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (1.9.4.post1)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from fiona) (0.7.2)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from fiona) (1.1.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from fiona) (21.4.0)\n",
      "Requirement already satisfied: certifi in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from fiona) (2022.12.7)\n",
      "Requirement already satisfied: click~=8.0 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from fiona) (8.1.3)\n",
      "Requirement already satisfied: six in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from fiona) (1.16.0)\n",
      "Requirement already satisfied: rasterio in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (1.3.7)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from rasterio) (61.2.0)\n",
      "Requirement already satisfied: numpy>=1.18 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from rasterio) (1.22.4)\n",
      "Requirement already satisfied: snuggs>=1.4.1 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from rasterio) (1.4.7)\n",
      "Requirement already satisfied: affine in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from rasterio) (2.4.0)\n",
      "Requirement already satisfied: click-plugins in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from rasterio) (1.1.1)\n",
      "Requirement already satisfied: certifi in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from rasterio) (2022.12.7)\n",
      "Requirement already satisfied: attrs in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from rasterio) (21.4.0)\n",
      "Requirement already satisfied: click>=4.0 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from rasterio) (8.1.3)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from rasterio) (0.7.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from snuggs>=1.4.1->rasterio) (3.0.9)\n",
      "Requirement already satisfied: scipy in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (1.7.3)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /opt/miniconda3/envs/ml/lib/python3.10/site-packages (from scipy) (1.22.4)\n",
      "File downloaded successfully and saved as 'config_file.json'.\n",
      "File downloaded successfully and saved as 'upland_gcps_200m.kml'.\n",
      "File downloaded successfully and saved as 'flightplan.kml'.\n",
      "File downloaded successfully and saved as 'manifest.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3338: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "/opt/miniconda3/envs/ml/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3338: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "packages = ['geopandas', 'pandas', 'numpy', 'shapely', 'pyproj', 'fiona','rasterio','scipy']\n",
    "\n",
    "for p in packages:\n",
    "  subprocess.check_call(['pip', 'install', p])\n",
    "\n",
    "#pip install -Uqq geopandas pandas numpy shapely pyproj fiona\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, Polygon, box, mapping\n",
    "from pyproj import CRS\n",
    "import fiona\n",
    "import requests\n",
    "import json\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.enums import Resampling\n",
    "from scipy.spatial import Voronoi\n",
    "\n",
    "fiona.drvsupport.supported_drivers['KML'] = 'rw'\n",
    "\n",
    "def download_file(url, save_path):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"File downloaded successfully and saved as '{save_path}'.\")\n",
    "    else:\n",
    "        print(f\"Error occurred while downloading file from '{url}'.\")\n",
    "        \n",
    "def get_metadata(attribute):\n",
    "  curl_command = [\"curl\", \"-H\", \"Metadata-Flavor: Google\", f\"http://metadata/computeMetadata/v1/instance/{attribute}\"]\n",
    "  result = subprocess.run(curl_command, capture_output=True, text=True)\n",
    "  return result.stdout.strip()\n",
    "\n",
    "def expand_to_gcps(focal_poly, gcps, gcp_cutoff=5, step_sz=30, base_buffer=50):\n",
    "    focal_poly = focal_poly.buffer(base_buffer)\n",
    "    count = sum(gcps.within(focal_poly.geometry.iloc[0]))\n",
    "    \n",
    "    if count < gcp_cutoff:\n",
    "        while count < gcp_cutoff:\n",
    "            focal_poly = focal_poly.buffer(step_sz)\n",
    "            count = sum(gcps.within(focal_poly.geometry.iloc[0]))\n",
    "    \n",
    "    return focal_poly\n",
    "\n",
    "def load_kml(path):\n",
    "  df = gpd.GeoDataFrame()\n",
    "\n",
    "  # iterate over layers\n",
    "  for layer in fiona.listlayers(path):\n",
    "      s = gpd.read_file(path, driver='KML', layer=layer)\n",
    "      df = pd.concat([df, s], ignore_index=True)\n",
    "  return df\n",
    "\n",
    "def copy_to_gcs(local_file_path, bucket_name):\n",
    "    command = ['gsutil', 'cp', local_file_path, 'gs://{}/'.format(bucket_name)]\n",
    "    try:\n",
    "        subprocess.run(command, check=True)\n",
    "        print('File copied to Google Cloud Storage successfully.')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print('Error occurred while copying the file to Google Cloud Storage:')\n",
    "        print(e)\n",
    "\n",
    "def mask_to_gdf(gdf, raster_path, output_path):\n",
    "    # Read the raster file\n",
    "    src = rasterio.open(raster_path)\n",
    "\n",
    "    # Reproject the GeoDataFrame to match the projection of the raster, if needed\n",
    "    gdf = gdf.to_crs(src.crs)\n",
    "\n",
    "    # Mask the raster using the GeoDataFrame's geometry\n",
    "    out_image, out_transform = mask(src, gdf.geometry, crop=True)\n",
    "\n",
    "    # Update the metadata of the cropped raster\n",
    "    out_meta = src.meta.copy()\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": out_image.shape[1],\n",
    "        \"width\": out_image.shape[2],\n",
    "        \"transform\": out_transform,\n",
    "        \"dtype\": out_image.dtype,\n",
    "        \"compress\": src.compression.value if src.compression else \"none\"\n",
    "    })\n",
    "\n",
    "    # Save the cropped raster to a new file\n",
    "    with rasterio.open(output_path, 'w', **out_meta) as dst:\n",
    "        # Use the original raster's block size and resampling method for better compression\n",
    "        dst.write(out_image)\n",
    "\n",
    "def process_images(batch, output_bucket, ortho_res, cutline, suffix):\n",
    "   # Create a temporary directory\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "    # Create an 'images' subdirectory\n",
    "    images_dir = os.path.join(temp_dir, 'images')\n",
    "    os.mkdir(images_dir)\n",
    "\n",
    "    for url in batch:\n",
    "        try:\n",
    "            subprocess.run(['wget', '-P', images_dir, url], check=True)\n",
    "            print(f\"File downloaded successfully from {url}\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error occurred while downloading file from {url}:\")\n",
    "            print(e)\n",
    "\n",
    "    # Execute OpenDroneMap Docker command\n",
    "    docker_command = [\n",
    "        \"docker\", \"run\", \"--rm\",\n",
    "        \"-v\", \"{}:/datasets/code\".format(temp_dir),\n",
    "        \"opendronemap/odm\", \"--project-path\", \"/datasets\",\n",
    "        \"--orthophoto-resolution\", f\"{ortho_res}\",\n",
    "        \"--fast-orthophoto\",\n",
    "        \"--force-gps\"\n",
    "    ]\n",
    "\n",
    "    process = subprocess.run(docker_command, check=True)\n",
    "    \n",
    "    ortho = os.path.join(temp_dir,'odm_orthophoto/odm_orthophoto.tif')\n",
    "    report = os.path.join(temp_dir,'odm_report/report.pdf')\n",
    "    ortho_new = ortho.replace('.tif',f'_{suffix}.tif')\n",
    "    report_new = report.replace('.pdf',f'_{suffix}.pdf')\n",
    "    \n",
    "    mask_to_gdf(cutline, ortho, ortho_new)\n",
    "    os.rename(report, report_new)\n",
    "\n",
    "    focal_files = [ortho_new, report_new]\n",
    "    \n",
    "    for f in focal_files:\n",
    "        copy_to_gcs(f, output_bucket)\n",
    "    \n",
    "    # Cleanup: Remove temporary directory\n",
    "    shutil.rmtree(temp_dir)\n",
    "\n",
    "def stop_instance(instance_name):\n",
    "    # Construct the gsutil command to stop the instance\n",
    "    gsutil_command = f'gsutil compute instances stop {instance_name}'\n",
    "\n",
    "    try:\n",
    "        # Execute the gsutil command using subprocess\n",
    "        subprocess.run(gsutil_command, shell=True, check=True)\n",
    "        print(f'Successfully stopped instance: {instance_name}')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f'Error stopping instance: {instance_name}')\n",
    "        print(e)\n",
    "\n",
    "def voronoi_finite_polygons_2d(vor, radius=None):\n",
    "    \"\"\"\n",
    "    Reconstruct infinite voronoi regions in a 2D diagram to finite\n",
    "    regions.\n",
    "\n",
    "    Source: https://gist.github.com/pv/8036995\n",
    "    \"\"\"\n",
    "\n",
    "    if vor.points.shape[1] != 2:\n",
    "        raise ValueError(\"Requires 2D input\")\n",
    "\n",
    "    new_regions = []\n",
    "    new_vertices = vor.vertices.tolist()\n",
    "\n",
    "    center = vor.points.mean(axis=0)\n",
    "    if radius is None:\n",
    "        radius = vor.points.ptp().max()*2\n",
    "\n",
    "    # Construct a map containing all ridges for a given point\n",
    "    all_ridges = {}\n",
    "    for (p1, p2), (v1, v2) in zip(vor.ridge_points, vor.ridge_vertices):\n",
    "        all_ridges.setdefault(p1, []).append((p2, v1, v2))\n",
    "        all_ridges.setdefault(p2, []).append((p1, v1, v2))\n",
    "\n",
    "    # Reconstruct infinite regions\n",
    "    for p1, region in enumerate(vor.point_region):\n",
    "        vertices = vor.regions[region]\n",
    "\n",
    "        if all(v >= 0 for v in vertices):\n",
    "            # finite region\n",
    "            new_regions.append(vertices)\n",
    "            continue\n",
    "\n",
    "        # reconstruct a non-finite region\n",
    "        ridges = all_ridges[p1]\n",
    "        new_region = [v for v in vertices if v >= 0]\n",
    "\n",
    "        for p2, v1, v2 in ridges:\n",
    "            if v2 < 0:\n",
    "                v1, v2 = v2, v1\n",
    "            if v1 >= 0:\n",
    "                # finite ridge: already in the region\n",
    "                continue\n",
    "\n",
    "            # Compute the missing endpoint of an infinite ridge\n",
    "\n",
    "            t = vor.points[p2] - vor.points[p1] # tangent\n",
    "            t /= np.linalg.norm(t)\n",
    "            n = np.array([-t[1], t[0]])  # normal\n",
    "\n",
    "            midpoint = vor.points[[p1, p2]].mean(axis=0)\n",
    "            direction = np.sign(np.dot(midpoint - center, n)) * n\n",
    "            far_point = vor.vertices[v2] + direction * radius\n",
    "\n",
    "            new_region.append(len(new_vertices))\n",
    "            new_vertices.append(far_point.tolist())\n",
    "\n",
    "        # sort region counterclockwise\n",
    "        vs = np.asarray([new_vertices[v] for v in new_region])\n",
    "        c = vs.mean(axis=0)\n",
    "        angles = np.arctan2(vs[:,1] - c[1], vs[:,0] - c[0])\n",
    "        new_region = np.array(new_region)[np.argsort(angles)]\n",
    "\n",
    "        # finish\n",
    "        new_regions.append(new_region.tolist())\n",
    "\n",
    "    return new_regions, np.asarray(new_vertices)\n",
    "\n",
    "def generate_points(poly, num, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    points = []\n",
    "    minx, miny, maxx, maxy = poly.bounds\n",
    "    while len(points) < num:\n",
    "        random_point = Point(np.random.uniform(minx, maxx), np.random.uniform(miny, maxy))\n",
    "        if (random_point.within(poly)):\n",
    "            points.append(random_point)\n",
    "    return [point.coords[0] for point in points]\n",
    "\n",
    "def calculate_voronoi_complexity(poly, points):\n",
    "    # compute Voronoi tesselation\n",
    "    vor = Voronoi(points)\n",
    "    \n",
    "    # create finite Voronoi polygons\n",
    "    regions, vertices = voronoi_finite_polygons_2d(vor)\n",
    "    \n",
    "    # construct the polygons and intersect with the original one\n",
    "    voronoi_polygons = [poly.intersection(Polygon(vertices[region])) for region in regions]\n",
    "    \n",
    "    # return only the valid ones (completely inside the original polygon)\n",
    "    valid_polygons = [p for p in voronoi_polygons if p.is_valid]\n",
    "\n",
    "    # calculate the perimeter and areas of each valid polygon\n",
    "    perimeters = [p.length for p in valid_polygons]\n",
    "    areas = [p.area for p in valid_polygons]\n",
    "    complexity = [x / y for x, y in zip(perimeters, areas)]\n",
    "    \n",
    "    return complexity, valid_polygons\n",
    "\n",
    "def optimize_voronoi_complexity(poly, num, max_iterations=1000, learning_rate=0.1, seed=None):\n",
    "    points = generate_points(poly, num, seed)\n",
    "    np.random.seed(seed)\n",
    "    mns = [] # to store complexity means at each iteration\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        complexity, polygons = calculate_voronoi_complexity(poly, points)\n",
    "        mn = np.mean(complexity)\n",
    "        mns.append(mn) # append current std dev to the list\n",
    "\n",
    "        # randomly select a point\n",
    "        point_idx = np.random.randint(0, len(points))\n",
    "        current_point = Point(points[point_idx])\n",
    "        \n",
    "        # Compute gradients by trying small movements in each direction\n",
    "        min_mn = mn\n",
    "        min_mn_direction = None\n",
    "        for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "            new_point = Point(current_point.x + dx * learning_rate, current_point.y + dy * learning_rate)\n",
    "            new_points = points.copy()\n",
    "            new_points[point_idx] = (new_point.x, new_point.y)\n",
    "            \n",
    "            new_complexity, _ = calculate_voronoi_complexity(poly, new_points)\n",
    "            new_mn = np.mean(new_complexity)\n",
    "            \n",
    "            if new_mn < min_mn:\n",
    "                min_mn = new_mn\n",
    "                min_mn_direction = (dx, dy)\n",
    "        \n",
    "        # If we found a direction that decreases the mean complexity, move the point\n",
    "        if min_mn_direction is not None:\n",
    "            dx, dy = min_mn_direction\n",
    "            points[point_idx] = (current_point.x + dx * learning_rate, current_point.y + dy * learning_rate)\n",
    "    \n",
    "    return polygons, mns\n",
    "\n",
    "temp_work = tempfile.mkdtemp()\n",
    "os.chdir(temp_work)\n",
    "\n",
    "#later these will be updated to gcloud metadata queries:\n",
    "branch = 'voronoi'\n",
    "survey = '230601_spurgepoly'\n",
    "array_idx = 0\n",
    "config_url = f'https://raw.githubusercontent.com/samsoe/mpg_aerial_survey/{branch}/surveys/{survey}/config_file.json'\n",
    "instance_name = f'odm-array-{array_idx}' #name of instance inferred from index\n",
    "\n",
    "#array_idx = int(get_metadata('array_idx')) #dynamic production version\n",
    "#config_url = get_metadata('config_url')#dynamic production version\n",
    "\n",
    "config_file = os.path.basename(config_url)\n",
    "download_file(config_url, config_file)\n",
    "\n",
    "with open(config_file, 'r') as json_file:\n",
    "    # Load the JSON data into a Python object\n",
    "    config = json.load(json_file)\n",
    "\n",
    "gcp_res = str(config['gcp_res'])\n",
    "gcp_grid_url = f'https://raw.githubusercontent.com/samsoe/mpg_aerial_survey/{branch}/gcp_kmls/upland_gcps_{gcp_res}m.kml'\n",
    "\n",
    "survey_res = config['survey_res']\n",
    "compute_array_sz = config['compute_array_sz']\n",
    "flight_plan_url = config['flight_plan_url']\n",
    "photo_manifest_url = config['photo_manifest_url']\n",
    "output_bucket =  config['output_bucket']\n",
    "gcp_editor_url = config['gcp_editor_url']\n",
    "\n",
    "gcp_grid = os.path.basename(gcp_grid_url)\n",
    "flight_plan = os.path.basename(flight_plan_url)\n",
    "photo_manifest = os.path.basename(photo_manifest_url)\n",
    "\n",
    "download_file(gcp_grid_url, gcp_grid)\n",
    "download_file(flight_plan_url, flight_plan)\n",
    "download_file(photo_manifest_url, photo_manifest)\n",
    "\n",
    "flight_roi = load_kml(flight_plan)\n",
    "gcps = load_kml(gcp_grid)\n",
    "\n",
    "crs_source = CRS.from_epsg(4326)\n",
    "crs_target = CRS.from_epsg(26911)\n",
    "\n",
    "# Set the source CRS of the GeoDataFrame\n",
    "flight_roi.crs = crs_source\n",
    "gcps.crs = crs_source\n",
    "\n",
    "# Reproject the GeoDataFrame to the target CRS\n",
    "flight_projected_src = flight_roi.to_crs(crs_target)\n",
    "gcps_projected_src = gcps.to_crs(crs_target)\n",
    "\n",
    "gcps_flight = gpd.sjoin(gcps_projected_src, flight_projected_src, how='inner', op='within')\n",
    "\n",
    "parts, means = optimize_voronoi_complexity(flight_projected_src.geometry[0], compute_array_sz, \n",
    "                                         learning_rate=30, max_iterations=1000, seed=0)\n",
    "\n",
    "base_poly = gpd.GeoDataFrame(geometry=[parts[array_idx]], crs = 26911)\n",
    "buffered_poly = expand_to_gcps(base_poly, gcps_flight, step_sz=30)\n",
    "manifest_df = pd.read_csv(photo_manifest)\n",
    "manifest_df['geometry'] = manifest_df.apply(lambda row: Point(row['longitude'], row['latitude']), axis=1)\n",
    "manifest_gpd = gpd.GeoDataFrame(manifest_df, geometry='geometry', crs=crs_source).to_crs(crs_target)\n",
    "target_photos = gpd.sjoin(manifest_gpd, gpd.GeoDataFrame(geometry=buffered_poly), op='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2901    https://storage.googleapis.com/mpg-aerial-surv...\n",
       "2902    https://storage.googleapis.com/mpg-aerial-surv...\n",
       "2903    https://storage.googleapis.com/mpg-aerial-surv...\n",
       "2904    https://storage.googleapis.com/mpg-aerial-surv...\n",
       "2905    https://storage.googleapis.com/mpg-aerial-surv...\n",
       "                              ...                        \n",
       "6679    https://storage.googleapis.com/mpg-aerial-surv...\n",
       "6680    https://storage.googleapis.com/mpg-aerial-surv...\n",
       "6681    https://storage.googleapis.com/mpg-aerial-surv...\n",
       "6682    https://storage.googleapis.com/mpg-aerial-surv...\n",
       "6683    https://storage.googleapis.com/mpg-aerial-surv...\n",
       "Name: url, Length: 833, dtype: object"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_photos['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function subprocess.run(*popenargs, input=None, capture_output=False, timeout=None, check=False, **kwargs)>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
